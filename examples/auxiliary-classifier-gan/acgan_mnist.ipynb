{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "from AutoGAN import GAN\n",
    "from AutoGAN.schemes.ACGAN_TrainingScheme import ACGAN_TrainingScheme\n",
    "\n",
    "import keras\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.visible_device_list = \"1\"\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "def build_generator():\n",
    "    img_rows = 28\n",
    "    img_cols = 28\n",
    "    channels = 1\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "    num_classes = 10\n",
    "    latent_dim = 100\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    #model.summary()\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(num_classes, 100)(label))\n",
    "\n",
    "    model_input = multiply([noise, label_embedding])\n",
    "    img = model(model_input)\n",
    "\n",
    "    return Model([noise, label], img)\n",
    "\n",
    "def build_discriminator():\n",
    "    img_rows = 28\n",
    "    img_cols = 28\n",
    "    channels = 1\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "    num_classes = 10\n",
    "    latent_dim = 100\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "\n",
    "    # Extract feature representation\n",
    "    features = model(img)\n",
    "\n",
    "    # Determine validity and label of the image\n",
    "    validity = Dense(1, activation=\"sigmoid\")(features)\n",
    "    label = Dense(num_classes+1, activation=\"softmax\")(features)\n",
    "\n",
    "    return Model(img, [validity, label])\n",
    "class save_images(keras.callbacks.Callback):\n",
    "    def __init__(self, model, name='gan'):\n",
    "        super(save_images, self).__init__()\n",
    "        self.full_model = model\n",
    "        self.name = name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.array([num for num in range(r*c)])\n",
    "        gen_imgs = self.full_model.generator_model().predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d.png\" % (self.name,epoch))\n",
    "        plt.close()\n",
    "\n",
    "def load_data():\n",
    "    (real_targets, real_label), (_, _) = mnist.load_data()\n",
    "    # Rescale -1 to 1\n",
    "    real_targets = real_targets / 127.5 - 1.\n",
    "    real_targets = np.expand_dims(real_targets, axis=3)\n",
    "    noise = np.random.normal(0, 1, (real_targets.shape[0], 100))\n",
    "    label_onehot = np.zeros((real_label.shape[0], 10))\n",
    "    for i in range(real_label.shape[0]):\n",
    "        label_onehot[real_label[i]] = 1\n",
    "    return noise, real_targets , real_label, label_onehot\n",
    "\n",
    "\n",
    "def acgan():\n",
    "    model = GAN(generator=build_generator(), discriminator=build_discriminator())\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    try:\n",
    "        shutil.rmtree('./images/acgan')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.makedirs(name='./images/acgan')\n",
    "    except:\n",
    "        pass\n",
    "    discriminator_kwargs = {'loss':['binary_crossentropy', 'sparse_categorical_crossentropy']*2, 'optimizer': optimizer, 'metrics':[]}\n",
    "    generator_kwargs = {'discriminator_loss':['binary_crossentropy', 'sparse_categorical_crossentropy'] , 'optimizer': optimizer}\n",
    "    model.compile(training_scheme=ACGAN_TrainingScheme(),\n",
    "                  generator_kwargs=generator_kwargs, discriminator_kwargs=discriminator_kwargs)\n",
    "    return model\n",
    "\n",
    "x, y, labels, label_onehot = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = acgan()\n",
    "model.fit(x=[x,labels], y=[y,labels], epochs=25, steps_per_epoch=800, batch_size=32,\n",
    "          generator_callbacks=[save_images(model=model, name='acgan')], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF 1.12 Keras 2.2.4",
   "language": "python",
   "name": "tf-1.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
